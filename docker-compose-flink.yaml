name: stream
services:
  notebook:
    extends:
      file: docker-compose-base.yaml
      service: notebook
    networks:
      datapipe_net:
  kafka-broker:
    extends:
      file: docker-compose-base.yaml
      service: kafka-broker
    networks:
      datapipe_net:
  generator:
    extends:
      file: docker-compose-base.yaml
      service: generator
    command: [ "sh", "-c", "tail -f /dev/null" ]
    volumes:
      - ./services/generator/src:/home/app/src
    scale: 1
  iceberg-rest:
    extends:
      file: docker-compose-spark.yaml
      service: iceberg-rest
    scale: 1
    networks:
      datapipe_net:
  minio:
    extends:
      file: docker-compose-spark.yaml
      service: minio
    scale: 1
    networks:
      datapipe_net:
  mc:
    extends:
      file: docker-compose-spark.yaml
      service: mc
    scale: 1
    networks:
      datapipe_net:
  flink-jobmanager:
    build: ./services/flink
    ports:
      - "8081:8081"
    command: jobmanager
    networks:
      datapipe_net:
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        state.backend: filesystem
        state.checkpoints.dir: file:///opt/flink/checkpoints
        state.savepoints.dir: file:///opt/flink/savepoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
      - BOOTSTRAP_SERVERS=kafka-broker:9092
      - RUNTIME_ENV=docker
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - JOB_MANAGER_HEAP_SIZE=1024m       # Total JVM heap for JobManager
      - FLINK_JM_HEAP=1024m               # (alternative, for older Flink)
      - FLINK_JM_HEAP_MB=1024             # (alternative, for older Flink)
      - FLINK_JM_CPU_CORES=1              # Logical CPU cores (if supported)
      - HADOOP_CONF_DIR=/opt/flink/conf/hadoop # Assuming this path exists and can be used for custom config
      - FLINK_PROPERTIES_hadoop.fs.s3a.endpoint=http://minio:9000
      - FLINK_PROPERTIES_hadoop.fs.s3a.access.key=admin
      - FLINK_PROPERTIES_hadoop.fs.s3a.secret.key=password
      - FLINK_PROPERTIES_hadoop.fs.s3a.path.style.access=true
      - FLINK_PROPERTIES_hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
      - FLINK_PROPERTIES_hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider # Or EnvironmentVariableCredentialsProvider
      - FLINK_PROPERTIES_fs.s3a.connection.ssl.enabled=false # Explicitly disable SSL for HTTP
    volumes:
      - ./services/flink/src:/opt/flink/app
      - ./services/flink/log/jobmanager:/opt/flink/log
      - ./services/flink/checkpoints/jobmanager:/opt/flink/checkpoints
      - ./services/flink/checkpoints/savepoints:/opt/flink/savepoints
      # - ./services/flink/config.yaml:/opt/flink/conf/config.yaml
    # entrypoint: ["/opt/flink/sql-client.sh", "embedded", "shell"]
  flink-taskmanager:
    build: ./services/flink
    depends_on:
      - flink-jobmanager
    command: taskmanager
    networks:
      datapipe_net:
    scale: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        state.backend: filesystem
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
      - BOOTSTRAP_SERVERS=kafka-broker:9092
      - RUNTIME_ENV=docker
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - TASK_MANAGER_HEAP_SIZE=1024m      # Total JVM heap for TaskManager
      - FLINK_TM_HEAP=1024m               # (alternative, for older Flink)
      - FLINK_TM_HEAP_MB=1024             # (alternative, for older Flink)
      - FLINK_TM_TASK_SLOTS=2             # Number of slots (parallelism)
      - FLINK_TM_CPU_CORES=1              # Logical CPU cores (if supported)
      - FLINK_PROPERTIES_hadoop.fs.s3a.endpoint=http://minio:9000
      - FLINK_PROPERTIES_hadoop.fs.s3a.access.key=admin
      - FLINK_PROPERTIES_hadoop.fs.s3a.secret.key=password
      - FLINK_PROPERTIES_hadoop.fs.s3a.path.style.access=true
      - FLINK_PROPERTIES_hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
      - FLINK_PROPERTIES_hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider # Or EnvironmentVariableCredentialsProvider
      - FLINK_PROPERTIES_fs.s3a.connection.ssl.enabled=false # Explicitly disable SSL for HTTP
networks:
  datapipe_net:
