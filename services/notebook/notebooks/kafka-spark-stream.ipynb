{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter_vim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run ./scripts/run-spark-streaming.sh at project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls /opt/spark/jars | grep kafka\n",
    "! ls /opt/spark/jars | grep avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\", \"admin\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"password\")\n",
    "\n",
    "# Create a SparkSession\n",
    "jars = [\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.4\"]\n",
    "spark = (SparkSession.builder.appName(\"KafkaStreaming\")\n",
    "     .master(\"local[1]\")\n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", \"true\")\n",
    "    .config(\"spark.sql.streaming.schemaInference\", \"true\")\n",
    "    .config(\"spark.jars.packages\", \",\".join(jars))\n",
    "    .config(\n",
    "        \"spark.sql.extensions\",\n",
    "        \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    )\n",
    "    .config(\"spark.sql.catalog.default\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.default.catalog\", \"spark\")\n",
    "    .config(\"spark.sql.catalog.default.type\", \"rest\")\n",
    "    .config(\"spark.sql.catalog.default.uri\", \"http://iceberg-rest:8181\")\n",
    "    .config(\"spark.sql.catalog.default.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "    .config(\"spark.sql.catalog.default.s3.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.sql.catalog.default.warehouse\", \"s3://warehouse/wh\")\n",
    "    .config(\"spark.sql.catalog.default.s3.access-key\", AWS_ACCESS_KEY_ID)\n",
    "    .config(\"spark.sql.catalog.default.s3.secret-key\", AWS_SECRET_ACCESS_KEY)\n",
    "    .getOrCreate()\n",
    "        )\n",
    "\n",
    "#    .config(\"spark.jars\", \"/opt/spark/jars/kafka-clients-3.4.1.jar\") \\\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "# Set up the Kafka configuration\n",
    "kafka_bootstrap_servers = \"kafka-broker:9092\"\n",
    "kafka_topic = \"brothers-karamazov\"\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls /home/app/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text format messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(file.endswith(\".txt\") for file in os.listdir(\"/home/app/output/\")):\n",
    "    spark.read.format(\"text\").load(\"/home/app/output/*.text\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avro format messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"line\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "if any(file.endswith(\".avro\") for file in os.listdir(\"/home/app/output/\")):\n",
    "    spark.read.format(\"avro\").option(\"schema\", schema).load(\n",
    "        \"/home/app/output/*.avro\"\n",
    "    ).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "for f in pathlib.Path(\"/home/app/output\").glob(\"*\"):\n",
    "    file_size = f.stat().st_size\n",
    "    print(f\"File: {f}, Size: {file_size / 1024 / 1024} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = spark.read.format(\"iceberg\").load(\"default.spark.text\")\n",
    "table.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "\n",
    "catalog = load_catalog(name=\"rest\", uri=\"http://iceberg-rest:8181\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.table_exists(\"spark.text\")\n",
    "table = catalog.load_table(\"spark.text\")\n",
    "table.schema().as_arrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.inspect.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.inspect.files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.scan().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
