{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter_vim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run ./scripts/run-spark-streaming.sh at project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls /opt/spark/jars | grep kafka\n",
    "! ls /opt/spark/jars | grep avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\", \"user\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"User@12345\")\n",
    "\n",
    "# Create a SparkSession\n",
    "jars = [\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.4\"]\n",
    "spark = (SparkSession.builder.appName(\"KafkaStreaming\")\n",
    "     .master(\"local[1]\")\n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", \"true\")\n",
    "    .config(\"spark.sql.streaming.schemaInference\", \"true\")\n",
    "    .config(\"spark.jars.packages\", \",\".join(jars))\n",
    "    .config(\n",
    "        \"spark.sql.extensions\",\n",
    "        \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    )\n",
    "    .config(\"spark.sql.catalog.default\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.default.catalog\", \"spark\")\n",
    "    .config(\"spark.sql.catalog.default.type\", \"rest\")\n",
    "    .config(\"spark.sql.catalog.default.uri\", \"http://iceberg-rest:8181\")\n",
    "    .config(\"spark.sql.catalog.default.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "    .config(\"spark.sql.catalog.default.s3.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.sql.catalog.default.warehouse\", \"s3://warehouse/wh\")\n",
    "    .config(\"spark.sql.catalog.default.s3.access-key\", AWS_ACCESS_KEY_ID)\n",
    "    .config(\"spark.sql.catalog.default.s3.secret-key\", AWS_SECRET_ACCESS_KEY)\n",
    "    .getOrCreate()\n",
    "        )\n",
    "\n",
    "#    .config(\"spark.jars\", \"/opt/spark/jars/kafka-clients-3.4.1.jar\") \\\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "# Set up the Kafka configuration\n",
    "BOOTSTRAP_SERVERS = \"kafka-broker:9092\"\n",
    "topic = \"message\"\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from iceberg table using spark\n",
    "table = spark.read.format(\"iceberg\").load(\"default.spark.message\")\n",
    "table.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "\n",
    "catalog = load_catalog(\n",
    "    \"default\",\n",
    "    **{\n",
    "        \"type\": \"rest\",\n",
    "        \"uri\": \"http://iceberg-rest:8181\",\n",
    "        \"s3.endpoint\": \"http://minio:9000\",\n",
    "        \"s3.access-key-id\": \"admin\",\n",
    "        \"s3.secret-access-key\": \"password\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.list_namespaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.table_exists(f\"spark.{topic}\")\n",
    "table = catalog.load_table(f\"spark.{topic}\")\n",
    "table.schema().as_arrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.inspect.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.current_snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.inspect.manifests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.scan().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://minio:9000\",\n",
    "    aws_access_key_id=\"admin\",\n",
    "    aws_secret_access_key=\"password\",\n",
    "    region_name=\"us-east-1\",  # MinIO typically defaults to 'us-east-1'\n",
    "    config=boto3.session.Config(\n",
    "        signature_version=\"s3v4\", s3={\"addressing_style\": \"path\"}\n",
    "    ),\n",
    ")\n",
    "response = s3_client.head_object(\n",
    "    Bucket=\"warehouse\",\n",
    "    Key=\"spark/text/metadata/snap-2813184513174423103-1-b8e3338d-386c-4376-9c31-6007e6ebbe8f.avro\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyiceberg\n",
    "\n",
    "pyiceberg.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
