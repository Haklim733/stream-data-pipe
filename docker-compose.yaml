services:
  notebook:
    container_name: notebook
    build:
      context: services/notebook
      dockerfile: Dockerfile
    networks:
      datapipe_net:
    depends_on:
      - rest
      - minio
    volumes:
      - ./services/notebook/warehouse:/home/iceberg/warehouse
      - ./services/notebook/notebooks:/home/iceberg/notebooks/
      - ./services/notebook/data:/home/iceberg/data
      - ./services/notebook/tmp:/tmp/spark-events # needed using spark image and docker file
      - ./services/kafka/src:/home/spark/kafka
      - ./services/flink/src:/home/spark/flink
    environment:
      - BOOTSTRAP_SERVERS=kafka-broker:9092
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - JUPYTER_PASSWORD=password
    ports:
      - 8888:8888
      - 8080:8080
      - 10000:10000
      - 10001:10001
  rest:
    image: apache/iceberg-rest-fixture
    container_name: iceberg-rest
    networks:
      datapipe_net:
    ports:
      - 8181:8181
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - CATALOG_WAREHOUSE=s3://warehouse/
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://minio:9000
  minio:
    image: minio/minio
    container_name: minio
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
    networks:
      datapipe_net:
        aliases:
          - warehouse.minio
    ports:
      - 9001:9001
      - 9000:9000
    command: ["server", "/data", "--console-address", ":9001"]
  mc:
    depends_on:
      - minio
    image: minio/mc
    container_name: mc
    networks:
      datapipe_net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    entrypoint: |
      /bin/sh -c "
      until (/usr/bin/mc config host add minio http://minio:9000 admin password) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc rm -r --force minio/warehouse;
      /usr/bin/mc mb minio/warehouse;
      /usr/bin/mc policy set public minio/warehouse;
      set +o history;
      /usr/bin/mc admin user add minio user user12345;
      echo -e "user\nuser12345" | /usr/bin/mc admin user add minio;
      /usr/bin/mc admin policy attach minio readwrite --user user;
      tail -f /dev/null
      "
  kafka-broker:
    image: apache/kafka:latest
    container_name: kafka-broker
    ports:
      - 9092:9092
      - 9093:9093
      - 19092:19092
    networks:
      datapipe_net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:19092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka-broker:9092,EXTERNAL://localhost:19092
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@localhost:9093
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_NUM_PARTITIONS=1
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true  # Kafka will automatically create topics if needed.
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1  # Since weâ€™re running one broker, one replica is enough.
      - KAFKA_LOG_RETENTION_HOURS=24  # Keep logs for 1 day
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0  # No delay for consumer rebalancing.
      - PATH=$PATH:/opt/kafka/bin
    volumes:
      - ./services/kafka/logs:/var/lib/kafka/data  # Store Kafka logs on your local machine.
  flink-jobmanager:
    container_name: flink-jobmanager
    build: ./services/flink
    depends_on:
      - minio
    ports:
      - "8081:8081"
    command: jobmanager
    networks:
      datapipe_net:
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        state.backend: filesystem
        state.checkpoints.dir: file:///opt/flink/checkpoints
        state.savepoints.dir: file:///opt/flink/savepoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
      - BOOTSTRAP_SERVERS=kafka-broker:9092
      - RUNTIME_ENV=docker 
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    volumes:
      - ./services/flink/src:/opt/flink/app
      - ./services/flink/log/jobmanager:/opt/flink/log
      - ./services/flink/checkpoints/jobmanager:/opt/flink/checkpoints
      - ./services/flink/checkpoints/savepoints:/opt/flink/savepoints
  flink-taskmanager:
    build: ./services/flink
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    command: taskmanager
    networks:
      datapipe_net:
    scale: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        state.backend: filesystem
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
      - BOOTSTRAP_SERVERS=kafka-broker:9092
      - RUNTIME_ENV=docker 
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
  # iceberg-ui:
  #     build: ./svelte-webapp
  #     ports:
  #       - "5173:5173"
  #     depends_on:
          # datapipe_net:
  #       - minio
  #     environment:
  #       - ICEBERG_REST_URL=http://iceberg-rest:8181
  #       - MINIO_URL=http://minio:9000
networks:
  datapipe_net: